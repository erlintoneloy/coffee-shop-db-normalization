Coffee Shop Data Engineering: Normalization & Multi-DB Migration
Centralizaci√≥n, normalizaci√≥n y ETL de datos transaccionales para una arquitectura de bases de datos h√≠brida.

üìù Visi√≥n General del Proyecto
Este proyecto aborda la problem√°tica real de la fragmentaci√≥n de datos en una cadena de cafeter√≠as en expansi√≥n. La informaci√≥n operativa resid√≠a en silos de datos heterog√©neos (HQ, CRM, POS y Proveedores) en formatos como Excel y CSV.

El objetivo fue dise√±ar e implementar un ecosistema de datos centralizado en PostgreSQL, optimizado para el rendimiento mediante vistas materializadas y preparado para una migraci√≥n fluida hacia entornos MySQL y IBM DB2.

üöÄ Objetivos Estrat√©gicos
Ingenier√≠a Inversa y Modelado: Extracci√≥n de l√≥gica de negocio desde archivos planos para la creaci√≥n de un Modelo L√≥gico/F√≠sico.

Normalizaci√≥n Avanzada: Refactorizaci√≥n de esquemas para eliminar redundancias y garantizar la integridad referencial.

Pipeline de Datos (ETL): Implementaci√≥n de procesos de extracci√≥n y transformaci√≥n para la unificaci√≥n de datos.

Arquitectura de Portabilidad: Generaci√≥n de activos agn√≥sticos al motor de base de datos para garantizar la interoperabilidad multicloud.

üõ†Ô∏è Stack Tecnol√≥gico
Base de Datos Principal: PostgreSQL 15+

Entornos de Destino: MySQL (phpMyAdmin) & IBM DB2.

Herramientas de Dise√±o: pgAdmin 4 ERD Tool.

Infraestructura: Entornos basados en Linux (Shell/Bash).

Control de Versiones: Git con flujo de trabajo basado en Rebase para un historial limpio.

üèóÔ∏è Ciclo de Vida del Desarrollo
1. Dise√±o y Normalizaci√≥n (ERD)
Se identificaron y corrigieron errores cr√≠ticos de integridad referencial en el dise√±o original. Se implement√≥ un esquema de 7 tablas relacionadas que cubren desde el personal (staff) hasta el detalle granular de las ventas (sales_detail).

2. Implementaci√≥n y Troubleshooting
Durante el despliegue, se superaron restricciones de interfaz gr√°fica mediante scripts avanzados de consola SQL.

Dominio de SQL COPY: Uso del comando COPY para la exportaci√≥n directa desde el servidor, evadiendo bloqueos de portapapeles y permisos de navegador.

Administraci√≥n de Sistemas: Gesti√≥n de directorios de sistema (/tmp y cach√© de credenciales) para la manipulaci√≥n de archivos CSV de gran tama√±o.

3. Optimizaci√≥n de Consultas
Creaci√≥n de Vistas Materializadas para acelerar el acceso a datos cr√≠ticos de marketing y reportes de n√≥mina, permitiendo una reducci√≥n significativa en el tiempo de ejecuci√≥n de consultas complejas.

üìÇ Estructura del Ecosistema
/scripts: Diccionario de datos SQL (DDL/DML) y reportes CSV generados.

/docs: Evidencias de ejecuci√≥n (Tasks 5A - 10) y documentaci√≥n de validaci√≥n.

GeneratedScript_personal.sql: L√≥gica de negocio optimizada y corregida.

üí° Nota de Ingenier√≠a y Portabilidad
Estado del Proyecto: El pipeline se complet√≥ exitosamente hasta la fase de Exportaci√≥n y Validaci√≥n de Datos.

Ante restricciones de infraestructura externa para la carga final en DB2, se entregaron archivos CSV estandarizados y saneados. Estos activos han sido validados para garantizar una carga de datos zero-error en cualquier motor relacional compatible, cumpliendo con los est√°ndares de interoperabilidad requeridos por la empresa.

C√≥mo explorar este proyecto
Revisar el Modelo: Dir√≠gete a /docs para visualizar el esquema l√≥gico corregido.

Ejecutar el Esquema: Utiliza GeneratedScript_personal.sql en una instancia de PostgreSQL.

Consultar Datos: El archivo CoffeeData.sql contiene los registros reales listos para an√°lisis.